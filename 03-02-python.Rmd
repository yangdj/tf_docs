# Python

1. Environment Management
    1. venv
        1. create virtual environment: `python3 -m venv virtual-name`
        2. remove virtual environment: `rm -rf virtual-name/`
        3. activate virtual environment: `source virtual-name/bin/activate`
        4. quit the environment: `deactivate`
    2. conda
        1. Windows: may need add `anaconda\Library\bin` to  `PATH` environment variable to find `conda`
        2. version info: `conda --version`
        3. update: `conda update conda`
        4. list all environments: `conda info --envs`
        5. create virtual environment: `conda create --name vtl-name python=3.5`
        6. activate virtual environment: `conda activate vtl-name`
        7. quit virtual environment: `conda deactivate`
        8. remove virtual environment: `conda remove --name vtl-name --all`
        9. add new channel when `packages not available`: `conda config --append channels conda-forge`
        10. **Use Anoconda Prompt to execute when faild in cmd environment**
2. Package Management
    1. conda
        1. `conda list pkg`
        2. `conda search pkg`
        3. `conda install pkg(=1.1.1)`
        4. `conda remove pkg`
        5. `conda update pkg`
    2. pip
        1. Configuraton
            1. `~/.pip/pip.conf`: for Linux and OSX
            2. `~\pip\pip.ini`: for Windows

            ```ini
            [global]
            index-url = https://pypi.tuna.tsinghua.edu.cn/simple
            [install]
            trusted-host = https://pypi.tuna.tsinghua.edu.cn
            ```
        2. Commands
            1. `pip install package`
            2. `pip uninstall package`
            3. `pip install --upgrade package`
            4. `pip list package`
            5. `pip show package`
            6. `pip search package`
            7. `pip freeze > requirements.txt`
            8. `pip install -r requirements.txt`
3. Common Packages
    1. Databases
        1. MySQL
            1. `mysqlclient`
            2. `pymysql`
        2. PostgreSQL: `psycopg2-binary`
        3. SQLServer
            1. `pymssql`
            2. dependencies
                1. `freetds-devel`: for `sqlfont.h`
                2. `unixODBC-devel`: for sql.h
                3. `C_INCLUDE_PATH`: search `sql.h` and other header files
        
                ```sh
                yum install freetds-devel unixODBC-devel
                export C_INCLUDE_PATH=/usr/include
                ```
        4. Hive
            1. `pyhive[hive]`
            2. dependencies
                * `thrift-sasl`: when meets `TSaslClientTransport' object has no attribute 'readAll'`
        
                ```sh
                yum install cyrus-sasl-devel cyrus-sasl-plain thrift-sasl
                ```
        5. SQLAlchemy
            1. connection string: `prefix://username:password@host:port/databasename?parameter=value`
            2. prefix:
                1. MySQL: `mysql+pymysql`
                    1. parameters: `charset=utf8`
                2. PostgreSQL: `postgresql+psycopg2`
                3. SQLServer: `mssql+pymssql`
    2. Data Processing
        1. ipython
            1. `ipython profile create <name>`: create configuration file under `$IPYTHONDIR `
            2. `ipython profile locate`
            3. `ipython profile list`
        2. numpy
        3. pandas
        4. line_profiler
        5. sqlparse
        6. sql-metadata
    3. visualization
        1. matplotlib
        2. seaborn
    4. ML
        1. scipy
        2. scikit-learn
        3. tensorflow
        4. keras
    5. Tools
        1. jupyter
            1. commands
                1. `juypter notebook --generate-config`: generate config file in directory `${JUPYTER_CONFIG_DIR}`
                2. `jupyter notebook --no-browser --port=5000 --ip=0.0.0.0`: default port 8888
                3. `jupyter notebook password`:  set jupyter login password, or use the following method
                4. `python -c "from notebook.auth import passwd; print(passwd('jupyter'))"`
            2. configurations
                1. `${JUPYTER_CONFIG_DIR}/jupyter_notebook_config.py`

                    ```python
                    # ${JUPYTER_CONFIG_DIR}/jupyter_notebook_config.py
                    import os                                                                                 
                    import sys                                                                                
                                                                                                              
                    #  for Mac, set browser value definitely; otherwise jupyter will not open browser automatically                                 
                    if sys.platform == "darwin":                                                              
                        c.NotebookApp.browser = "Safari"
                                                                        
                    c.NotebookApp.notebook_dir = "/server/proj/py-lrn"
                    #c.NotebookApp.password = "sha1:9e799b2236aa:01085662782c7813128637089192f836901b196d"
                    ```
                2. `ipython-notebook.service`

                    ```ini
                    # /usr/lib/systemd/system/ipython-notebook.service
                    [Unit]
                    Description=Jupyter Notebook Server
                    
                    [Service]
                    Type=simple
                    Environment="LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib"
                    Environment="PATH=/usr/local/bin:/usr/bin:$PATH"
                    ExecStart=/server/proj/.env/py-lrn/bin/jupyter notebook --ip=0.0.0.0 --no-browser                                                   
                    User=yang
                    Group=yang
                    
                    [Install]
                    WantedBy=multi-user.target
                    ```
4. Syntax
    1. Variable
        1. `[a-zA-Z0-9]` and other unicode characters
        2. the first character should be digits, `[0-9]`
        3.  case sensitive
        4.  should not be keywords, that name can be with a trailing underscore `_`, `class_`
    2.  Keywords
        1. `help("keywords")`: list keywords
    3.  Naming Conventions
        1. never use the character `l` (lower case `L`, like one), `O` (like zero), `I` as single variable names
        2. use ASCII-only characters and English words whenever feasible
        3.  underscore notation
            1. variable
            2. function
    4. Operators
        1. `+, -, * /, %`
        2. `//`: floor division
        3. `**`: exponentiation, `3 ** 2 => 9`
        4. `+x, -x`: unary plus or minus number, `+3, -3`
        5. `~x`: bitwise negation
        6. `&, |, ^`: bitwise And, Or, XOR
        7.  `<, <`: shift left, right
        8.  `>, >=, <, <=, ==, !=`: comparision
        9.  `and, or, not`: boolean And, Or, Not
        10. `in`: element of
        11. `=, +=, -=, *=, /=, ...`
    5. Controls
        1. Conditional Statement: `if: ... elif: ... else: ...`
        2. Loops
            1. `while conditin: ... else: ...`
            2. `for a in c: ... else: ...`
        3. break: exit the loop. If a loop is left by `break`, the `else` part is not executed
        4. continue: stop currrent iteration and start then next iteration by checking the condition
    6. Input & Output
        1. console
            1. `input()`
            2. `print()`
        2. file
            1. `f = open(file, mode)`
                1. `r`: read file in text mode
                2. `rb`: read file in binary mode
                3. `w`: writing, truncate the file if it already exists
                4. `a`: append to the file
            2. `f.read(n=None)`: read file into a one string object
            3. `f.readline()`: read one line
            4. `f.readlines()`: return all lines to a list
            5. `f.write(str)`: write string to the file
            6. `f.close()`
            7. `f.tell()`: tell the position of the current stream
                1. `0`: at the first character of the file
            8. `f.seek(offset, start=0)`: move to specified position, for start value
                1. `0`: beginning of the file
                2. `1`: the current position for binary reading
                3. `2`: the end of file for binary reading
    7.  Function:
        1. Definition: use `def` to define a function with a name
        2. Parameters:
            1. can be empty when defined
            2. can be positional or keyword, `f(1, 2, a=3, b=4)`
            3. can have default value when defined, `__defaults__` is created
            4. `*args`: arbitrary number of parameters. `*` in the front of the last positional parameter name denote it as a tuple reference, `args` is a tuple
            5. `**kwargs**`: arbitrary number of keyword parameters. `kwargs` is a dict
        3. Body
            1. Return
                1. `None` will return when no return used, or just return without an expression
                2. `return expr` will return `expr` value
                3. `return` will stop the function
                4. `return (a, b)` can return multiple values using tuple, list or other types
            2. Side Effect: in addition to produce a return value, the function modifies the caller's environment in other ways, including:
                1. modify a global or static variable
                2. modify one of its arguments
                3. raise an exception
                4. write data to a display or file
                5. ...
            3. Variable Scope: variable names are by default local to the function
                1. `global`: made the vairable global, not local
                2. `nonlocal`: a nonlocal variable has to be defined in the enclosing function scope
                3. a variable can't be both local and global, otherwise `UnboundLocalError` will be raised
    8.  Modules: Every file with file extension `.py` and proper python code can be seen or is a module.
        1. import: all objects in the module can be accessed using `import`:
            1. `import math`: import a module
            2. `import math as mathematics`: import a module with a new na
            3. `import math, random`: import mutiple mudul
            4. `from math import pi, sin`: import certain objects of a modu
            5. `from math import pi, pow as power, sin as sinus`: import objects with a new na
            6. `from math import *`: import everything from a module, except those beginning with an underscore `_`, not recommended, possible for interactive sessions
        2. Search Path: modules should be on search path when import
            1. the directory where the file is executed
            2. `PYTHONPATH` environmental variable when set
            3. standard installation path
        3.  Reload: every module can only be imported once per interpreter session or in a program. Restart the interpreter or reload the module again when some code modified
            1. `from importlib import reload; reload(a_module)`: python3.4+
            2. `from imp import reload; reload(a_module)`: python3+, deprecated since 3.4
            3. `reload(a_module)`: python2
        4.  `__name__`: a module can be run as a script as if it had been imported, with exception that its `__name__` set to `__main__`
    9. Packages
        1. A package is basically a directory with python files and a file with the name `__init__.py`, which can be empty or contains valid code. It structures module namespace using **dotted modules names**. `A.B` stands for a submodule named `B` in a package named `A`.
        2. An `__all__` list in the `__init__.py` can list module and packages names to be imported when import a package using `*` in the form `from package import *`.
    10. Exception
        1. `try except`: start an exception handling
        2. `else`: optional after all the exceplt clauses, executed if try clause does not raise an exception
        3. `finally`: clean-up or termination clauses, they must be executed under all circumstances, whether an exception occurred or not
        4. `raise`: raise an exception, when just raise, the exception will be thrown again
    
        ```python
        try:
            statement_1
            ...
        except IOError as e:
            statement_1
            ...
        except ValueError:
            statement_1
            ...
        except (NameError, TypeError):
            statement_1
            ...
        except:
            statement_1
            ...
        else:
            statement_1
            ...
        finally:
            statement_1
            ...
        ```
    11. Iterable & Iterator
        1. Iterable: object can be used in `for loop` statement. It should have method `__iter__` which returns an iterator or `__getitem__` with sequential indexes starting with 0
        2. Iterator: subset of iterable. It should have methods `__iter__` which returns itself and `__next__` which will be used when the  function `next()` is called. When a for loop is executed, the `for` statement calls `iter()` on the object. If successful, the `iter` will return an iterator that defines `__next__()`, which accesses elements of the object one at a time. the `__next__()` method will raise a `StopIteration` except if there are no further elements available. The `for` loop will terminate as soon as it catches a `StopIteration` exception.
    
        ```python
        letters = ["A", "B", "C"]
        for letter in letters:
            print(letter)
    
        letters_iterator = iter(letters)
        while True:
            try:
                letter = next(letters_iterator)
                print(letter)
            except StopIteration:
                break
        ```
    12. Generator: A generator is a function returning a generator object which is also an iterator (not vice versa) producing values lazily. The advantage of generators consist in automatically creating methods `__iter__()` and `__next__()`. There are two types of generators:
        1. generator function: use `yield` instead of `return` to produce values. If there is a `return` statement in the code of a generator, the execution will stop with a `StopIteration` exception
        2. generator comprehension: use `()` similar to list comprehension
    13. lambda: `lambda argument_list: expression`
    14. Decorators
        When define decorators, take into account that the attributes of origininal functions will be lost after the decoration
        1. `__name__`
        2.  `__doc__`
        3.  `__module__`
        it can be solved this way:

        ```python
        def greeting(func):
            def function_wrapper(x):
                """ function wrapper of greeting """
                print("Hi " + func.__name__ + " returns:")
                return func(x)
            function_wrapper.__name__ = func.__name__
            function_wrapper.__doc__ = func.__doc__
            function_wrapper.__module__ = func.__module__
            return function_wrapper
        ```
        or using `functools.wraps`:
        ```python
        from functools import wraps
        def greeting(func):
            @wraps(func)
            def function_wrapper(x):
                """ function wrapper of greeting """
                print("Hi " + func.__name__ + " returns:")
                return func(x)
            return function_wrapper
        ```
        Class-based decorator should make the class callable, which has `__call__()` method:
    
        ```python
        class Memoize:
            def __init__(self, fn):
                self.fn = fn
                self.memo = {}
    
            def __call__(self, *args):
                if args not in self.memo:
                    self.memo[args] = self.fn(*args)
                return self.memo[args]
    
        @Memoize # fib = Memoize(fib)
        def fib(n):
            if n == 0:
                return 0
            elif n == 1:
                return 1
            else:
                return fib(n-1) + fib(n-2)
    
        fib(40)
    
        # the corresponding function-based way:
        def memoize(f):
            memo = {}
            def helper(x):
                if x not in memo:            
                    memo[x] = f(x)
                return memo[x]
            return helper
    
        @memoize
        def fib(n):
            if n == 0:
                return 0
            elif n == 1:
                return 1
            else:
                return fib(n-1) + fib(n-2)
        ```
5. Datatypes 
    1. basic
        1. bool: subclass of `int`
            1. `True`
            2.  `False`, following values will be considered as `False` value
                1. `False`
                2. `0`
                3. `0.0`
                4. `0j`
                5. `""`
                6. `()`
                7. `[]`
                8. `{}`
                9. `None`
        2. int: unlimited size in Python3, no `long` type as in Python2
            1.  `1234`: normal integer, base 10
            2.  `0b11`: binary, base 2, prefix by `0b` or `0B`
            3.  `0o1234`: octal, base 8, prefix by `0o` or `0O`
            4.  `0x1234`: hexadecimal, base 16, prefix by `0x` or `0X`
        3. float: `1.0`
        4. complex: `3+2j`
        5. str
            1. Properties
                1. sequences of pure Unicode characters in Python3, no specific encoding like UTF-8
                2. immutable
            2. Represtentations
                1. `"hello"`: double quotes
                2. `'hello'`: single quotes
                3. `"""hello"""`: triple double quotes
                4. `'''hello'''`: triple single quotes
                5. `r"hello"`: raw string, backslashes are not handleed in any special way, useful in REs processing for simplicity
                6. `b"hello"`: bytes, see `bytes`
            3.  Escaping: use backslash `\`
                1. `\\`: backslash
                2. `\'`: single quote
                3. `\"`: double quote
                4. `\a`: BEL, Bell
                5. `\b`: BS, Backspace
                6. `\t`: TAB
                7. `\n`: LF, Linefeed
                8. `\f`: FF, formfeed
                9.  `\v`: VT, Vertical Tab
                10. `\r`: CR, Carrige Return
                11. `\ooo`: octal value `ooo`
                12. `\xhh`: hex value `hh`
                13. `\uxxxx`: 16-bit hex value `xxxx` (Unicode only)
                14. `\Uxxxxxxxx`: 32-bit hex value `xxxxxxxx` (Unicode only)
                15. `\N{name}`: named `name` in Unicode database (Unicode only)
            4.  Operations
                1. `.upper()`
                2. `.lower()`
                3. `.replace()`
                4. `.find()`
                5. `.join()`
                6. `.split()`
                7. `m=str.maketrans("abc", "ABC")`
                8. `.translate(m)`
                9.  `.captalize()`
                10. `.rstrip()`
                11. `.ljust(width. fillchar= "")`
                12. `.rjust(width. fillchar= "")`
                13. `.center(width, fillchar=" ")`
                14. `.zfill(width)`: pad a numeric string with zeros on the left, the string is never truncated
                15. `.format(*args, **kwargs)`
                    the string template contains one or more format codes (fields to be replaced) embedded in constant text. They are surrounded by `{}`. if a brace character has to be printed, it has to be escaped by doubling it, `{{`, `}}`, The format codes has structure `{index:[flags][options][width][.precision]type}`
                    1. index: `{0}, {1}, {2}, ...; {}, {}, {}...; {a}`: for the first, second and ... in `args`, and keys in `kwargs`
                    2. flags:
                        1. `#`: used with type `o`, `x`, `X`, the value is preceded with `0o`, `0x`, `0X` respecitively
                        2. `0`: zero padded for numeric values
                        3. `-`: the converted value is left adjusted, blank spaces is inserted
                        4. `+`: a sign `+` or `-` will preceded the conversion, overrides a space flag
                        5. other padding character, should specify options
                    3. options:
                        1. `>`: right justify, default for numbers
                        2. `<`: left justify: default for strings,
                        3. `^`: center aligned 
                        4. `0`: 0 will be padded for numbers
                        5. `,`: use commas for a thousand separator
                        6. `=`: force the padding to be placed after the sign (if any) and before the digits
                    4. width: total number of string length, including decimal point
                    5. precision: the number following decimal point
                    6. type:
                        1. `d`: decimal integer
                        2. `i, u`: same as `d`
                        3. `o`: octal
                        4. `x, X`: hexadecimal
                        5. `f, F`: float point
                        6. `e, E`: floting point exponential format
                        7. `g, G`: same as `e, E`, if exponent is greater than -4 or less than precision; otherwise `f, F` is used
                        8. `c`: single character, accepts integer or single character string
                        9. `r`: string from `repr()`
                        10. `s`: string from `str()`
                        11. `%`: percent number, when in `%` format, then just return `%` character
                    
                    Since Python3.6, `f""` sring literals is introduced:
        
                    ```python
                    price = 11.23
                    f"Price in Swiss Franks: {price * 1.086:5.2f}"
                    ```
        6. bytes
            1. immutable
            2.  a sequence of small integers. the elements are in the range 0 to 255
            3.  printed as a sequence of ASCII characters
            4. not possible to mix text and data in Python3, otherwise raise TypeError
            5.  `"hello".encode("UTF-8"); b"hello"`
            6.  `b"hello".decode("UTF-8")`
        7. bytearray
            1. sequential
            2. mutable
        8. list:
            1. Properties:
                1. a sequence of elements, which can be arbitrary objects, and can be nested
                2. mutable
            2.  initialization
                1. `s = []`: empty list
                2. `s = [1, "hello", False]`: a list of mixed data types
                3. `s = [1, [1, 2, 3]]`: a nested list
            3.  operations
                1. `.append()`: append object to the end of the list
                2. `.pop(index=-1)`: remove and return element at index (default last)
                3. `.insert(index, object)`: insert object before index
                4. `.remove(value)`: remove the first occurrente of value
                5. `.extend(iterable)`: extend list by appending elements from the iterable
                6. `.clear()`: remove all items from list
                7. `.copy()`: return a shallow copy of the list
                8. `.count(value)`: return number of occurrences of value
                9. `.index(value, start=0, stop=last)`: return the first index of value, raise ValueError if the value is not present
                10. `.reverse()`
                11. `.sort()`
                12. `+`: not recommend for list, much slow, choose `.append()`, `.extend()`, or `+=`
        9. tuple: like list, but immutable and faster
            1.  Initialization
                1. `s = ()`: empty tuple
                2. `s = (1, "hello", False)`
        10. dict:
            1.  Properties
                1. unordered
                2. mutable
                3. keys must be immutable data types
            2.  Initialization
                1. `d = {}; d = dict()`: an empty dict
                2. `d = {"a": 10, "b": 20}; d = d(a=10, b=20)`
                3. `dict(mapping)`
                4. `dict(iterable)`
            3.  Access: using keys
                1. `d["a"]`
                2. `d["a"] = 30`
            4.  Methods
                1. `.keys()`
                2. `.values()`
                3. `.items()`
                4. `list(.keys()), list(.values()), list(.items())`: turn the result to list
                5. `del d["a"]`: delete key "a" together with its value
                6. `k in d; k not in d`
                7. `.get(key, default=None)`
                8. `.pop(key), .pop(key, default)`
                9. `.copy()`: a shallow copy
                10. `.clear()`: clear the dict, set it to empty
                11. `.update(dict)`: merge and overwritten the objects with given dict
        11. set
            1.  Properties
                1. unordered
                2. mutable
                3. elements are immutable and unique
            2.  Initialization
                1. `set(); {"a", "b", "c"}`: an empty set, `{}` creates an empty dict
                2. `set(iterable)`
            3.  Methods
                1. `.add(el)`
                2.  `.discard(el)`: an element removed from this set. If el is not in this set, nothing will be done
                3.  `.remove(el)`: like `.discard()`, but a KeyError will be raised
                4.  `.pop()`: remove and return an arbitray set element, a KeyError is raised if the set is empty
                5. `.clear()`
                6. `.copy()`: a shallow copy
                7.  `.issubset(y); x <= y`:  True, if the object is a subset of y
                8.  `x < y`: True if x is a proper set (真子集)of y
                9.  `.issuperset(y); x >= y`: True, if the object is a superset of y
                10. `x > y`: True if x is a proper superset of y
                11. `.isdisjoint(y)`: return True if two sets have a null intersection
                12. `.difference(y); x - y; x - y - z`: return difference of two or more sets as a new set, leaving the original set unchanged
                13. `.difference_update(y)`: remove all elements of another set from this set
                14. `.union(y); x | y`: return the union of two sets as a new set
                15. `.intersection(y); x & y`: return the intersection of two sets as a new set
        12. frozenset: like set, but immutable
            1.  Initialization
                1. `frozenset()`: an empty frozenset
                2. `frozenset(iterable)`
            2. common
    2.  Collection: data contains several elements.
        1.  `in, not in`: check if an element contained, `"hello" in s; "hello1" not in s`
        2.  `len(s)`
    3. Sequential: elements are ordered in a defined sequence and they can be accessed via indices. The sequence implements `getitem()` and `len()` method. Python starts from 0.
        1.  `s[0]`: get the first element
        2.  `s[-1]`: get the last element
        3.  `s[-1]`: get the second last element
        4.  `s[0][0]`: get the first element of first element
        5.  `s[start:end]`: get from `s[tart]` to `start[end]`, except `start[end]`
        6.  `s[start:end:step]`: get `s[start], s[start+1*step], ..., s[start+i*step]` where `start+i*step<end`
        7.  `s[:]`: a shallow copy
        8.  `len(s)`
        9.  `+`: concatenate two sequence
        10. `*`: repeat sequence n times
    4. Mutable: whether the elements can be modified
6. common functions
    1.  builtins
        1. `help()`
        2. `input(prompt=None)`: read from standard input
        3. `print(value, ..., sep=" ", end="\n", file=sys.stdout, flush=False)`: function in Pythone, while statement in Python2
        4. `id()`: the identity of an object, memory address in CPython
        5. `locals()`: return current scope's local variables
        6. `type()`
        7. `str()`
        8. `len()`
        9. `repr()`
        10. `sorted()`
        11. `range()`
            1. `range(stop)`: return s, where 1 <= s < stop
            2. `range(start, stop)`: return s, where start <= s < stop
            3. `range(start, stop, step=1)`: return s where start<= s < end, with every step
        12. `dir()`:
            1. `dir()`: list names in the current local scope
            2. `dir(math)`: list valid attributes and methods within the module `math`
        13. `enumerate(a, start)`: `start` default 0, can be any integer
        14. `zip(a, b)`
        15. `ord()`: return the unicode code print for a one-character string
        16. `chr()`: return a Unicode character from number, 0 <= i <= 0x10ffff
        17. `int(x, base=10)`: `base=0` means to interpret the base from the string as an integer literal
        18. `hex()`: convert a number to hexadecimal strings
        19. `oct()`: conver to octal strings
        20. `bin()`: convert to binary strings
        21. `issubclass()`
        22. `isinstance()`: `isinstance(True, int) => True`
        23. `callable`: whether the object can be called
        24. `hasattr()`
        25. `getattr()`
        26. `setattr()`
        27. `class.__mro__`
        28. `class.mro()`
        29. `class.__bases__`
        30. `self.__class__.__name__`
        31. `self.__class__.__module__`
        32. `map()`
        33. `filter()`
    2.  functools
        1.  `functools.reduce()`
    3.  locale
        1. `locale.getpreferredencoding(False)`
    4.  sys
        1.  `sys.stdin`
        2.  `sys.stdout`
        3.  `sys.stderr`
        4.  `sys.exit(1)`: exit program
        5.  `sys.argv`:
            1. `sys.argv[0]`: script name
            2. `sys.argv[1]`: the first argument
            3. `sys.argv[2], ...`: the second and so on argument
        6.  `sys.path`: `module search path; path[0] is the script directory, else ''`
        7.  `sys.prefix`
        8.  `sys.platform`
        9.  `sys.version_info`
        10. `sys.version.[major, minor, micro]`
        11. `sys.builtin_module_names`
        12. `sys.getsizeof(): size of objects in bytes`
        13. `sys.modules.get('multiprocessing')`
        14. `sys.exc_info() => (etype, value, tb)`: `tb` now can be get from exception's `__traceback__` attribute since Python3
    5.  traceback
        1.  `traceback.extract_tb(tb)`: return a `FrameSummary` object, which have following attributes:
            1. `filename`: filename for the frame
            2. `lineno`: the line within the filename for the frame
            3. `name`: function name or method executing when the frame was captured
            4. `line`: the corresponding line source code with leading and trailing whitespace stripped
            5. `locals`: local variables in the current frame
        2.  `traceback.print_tb(tb)`
        3.  `traceback.format_tb(tb)`: return with strings, not print the result
        4.  `traceback.print_exception(etype, value, tb)`
        5.  `traceback.format_exception(etype, value, tb)`
        6.  `traceback.print_exc() <=> traceback.print_exception(*sys.exc_info())`
        7.  `trackback.format_exc()`
        8.  `traceback.extract_stack()`
        9.  `traceback.format_stack()`
        10. `traceback.print_stack()`
    6.  os
        1.  `os.environ`
        2.  `os.fspath(filename)`
        3.  `os.path.normcase(filename)`
        4.  `os.path.abspath(__file__)`
        5.  `os.path.dirname()`
        6.  `os.path.basename(dirname)`
        7.  `os.path.splitext(filename)`
        8.  `os.path.join(dirname, filename)`
        9.  `os.getpid()`
    7.  math
        1.  `math.pi`
        2.  `math.e`
        3. `math.sqrt()`
        4. `math.sin()`
        5. `math.cos()`
        6. `math.tan()`
        7. `math.pow()`
    8.  time
        1.  `time.time()`
    9.  itertools
        1.  `itertools.zip_longest(a, b)`
    10. random
        1. `random.random()`: return s, that 0 <= s < 1
        2.  `random.randint(m, n)`: return s, m <= s <= n
        3.  `random.choice(seq)`: return s from seq
        4.  `random.sample(population, k)`: choose k unique random elements from a population sequence or set
    11. thread
        1.  `threading.RLock(); lock.acquire(); lock.release()`
        2.  `threading.get_ident()`
        3.  `threading.current_thread().name`
    12. multiprocessing
        1.  `multiprocessing.current_process().name`
    13. string: a collection of string constants
        1. `string.ascii_uppercase`: `'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`
        2. `string.ascii_lowercase`: `'abcdefghijklmnopqrstuvwxyz'`
        3. `string.ascii_letters`: `ascii_lowercase + ascii_uppercase`
        4. `string.digits`: `'0123456789'`
        5.  `string.octdigits`: `'01234567'`
        6.  `string.hexdigits`: `string.digits + 'abcdef' + 'ABCDEF'`
        7.  `string.whitespace`: `' \t\n\r\v\f'`
        8.  `string.punctuation`: `` r"""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~""" ``
        9.  `string.printable`: `string.digits + string.ascii_letters + string.punctuation + string.whitespace`
    14. copy
        1. `copy.deepcopy()`
    15. dis
        1. dis.dis()
    16. urllib
        1. `urllib.request.urlopen()`

## Ansible

1. References
    1. [User Guide](https://docs.ansible.com/ansible/latest/user_guide/index.html)
    2. [builtin modules](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/)
    3. [ansible examples](https://github.com/ansible/ansible-examples)
    4. [YAML](#ff-yaml) and [YAML Syntax](https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html#yaml-syntax)
2. Dependencies
    1. Packages
        1. ansible
    2. Problems
        1. `libselinux-python aren't installed`: sets `SELINUX=disabled` in `/etc/selinux/config`
    3. Settings
        1. File
            1. `~/.ansible.cfg`: home directory
            2. `./ansible.cfg`: from current directory
            3. `/etc/ansible/ansible.cfg`: default path
            4. `ANSIBLE_CONFIG`: environment vairable to file path
        2. Contents
            1. `[defaults]`
                1. `deprecation_warnings=False`
                2. `inventory=/etc/ansible/hosts`
                3. `log_path=/var/log/ansible.log`
3. Concepts
    1. Control node: any machine with ansible installed
    2. Managed nodes: hosts managed with ansible, no need to install ansible
    3. Inventory: a list of managed nodes, an inventory file is also called a hostfile
        1. Settings
            1. `/etc/ansible/hosts`: default inventory file
            2. `ANSIBLE_INVENTORY`: environment variable to file path
            3. `-i path`: specify inventory file or directory path in commands, can use multiple times
        2. INI format
            1. hosts
                1. Types
                    1. `foo.example.com`: url
                    2. `192.168.0.122`: ip
                    3. `192.168.0.122:9000`: ip with port
                    4. `jumper ansible_host=192.168.0.122`: hosts with alias
                    5. `www[01:50].example.com`: numeric ranges of hosts ranges are inclusive
                    6. `www[01:50:2].example.com`: ranges with steps
                    7. `db-[a:f].example.com`: alphabetic  ranges of hosts
                2. Host variables
                    1. define
                       1. `var_name=value`: customized
                       2. `/.../host_vars/jumper[.yml, .yaml]`: put in host variable directory relative to the inventory or playbook file
                       3. `/.../host_vars/jumper/...`: put in host variable name directory
                    2. connection settings
                        1. `ansible_host=192.168.0.10`
                        2. `ansible_port=5555`: default 22 for ssh
                        3. `ansible_user=myuser`: user name to connect to the host
                        4. `ansible_password`: not recommended, use vaulted variable
                    3. ssh settings
                        1. `ansible_connection=[local, ssh]`: connction type to managed hosts
                    4. reomte settings
                        1. `ansible_python_interpreter=/usr/local/bin/python`: the target host python path
            2. groups
                1. Naming
                    1. `all`: default group, containing all hosts
                    2. `ungrouped`: default group, containing all hosts that don't have another group aside from group `all`
                    3. `[server]`: customized group name
                    4. `[server:children]`: make groups of groups using `:children`
                2. Group variables
                    1. define
                        1. `[server:vars]`: put variables under `:vars` part
                        2. `/.../group_vars/server[.yml, .yaml]`: put in group variable directory relative to inventory or playbook file
                        3. `/.../group_vars/server/...`: put in group variable name directory
                    2. settings
                        1. `ansible_group_priority: 1`: change variable merge order, default 1 

            ```ini
            192.168.1.111 ansible_user=hadoop
            jumper ansible_host=192.0.2.50 ansible_port=5555

            [server]
            aserver.example.com
            bserver.example.com
            jumper
            ```
    4. Collections: a distribution format including playbooks, roles, modules and plugins, using `ansible-galaxy` to install collections
    5. Modules: the units of code ansible executes, since ansible 2.10, modules are grouped in collections
        1. `ansible.builtin.command`: default module, do not support piping and redirects, use `shell` module
        2. `ansible.builtin.shell`
        3. `ansible.builtin.file`
            1. `path`: alias `dest`, `name`
            2. `src`
            3. `state`
                1. `directory`: similir to `mkdir -p`
                2. `file`: default, return `path` state, but will not be created if it does not exist
                3. `touch`: an empty file will be created if the `path` does not exist
                4. `absent`: delete files or directories recursively
                5. `link`
                6. `hard`
            4. `mode=600`
            5. `owner`
            6. `group`

            ```yaml
            file:
              path: "{{ proj_home }}"
              mode: 0755
              state: directory
              owner: "{{ remote_user }}"
              group: "{{ remote_user }}"
            ```
        4. `ansible.builtin.copy`
            1. `src`
            2. `desc`
        5. `ansible.builtin.template`
            1. `src`
            2. `dest`

            ```yaml
            template:
              src: "conf/{{ hadoop_version }}/{{ item }}.j2"
              dest: "{{ hadoop_base.conf_version }}/{{item}}"
              loop:
                - workers
                - masters
            ```
        6. `ansible.posix.synchronize`
            1. `src`
            2. `dest`

            ```yaml
            ansible.posix.synchronize:
              src: "{{ jdk_source_name }}"
              dest: "{{ java_bin_home }}"
            ```
        7.  `ansible.builtin.blockinfile`
            1. `path`
            2. `create: yes`: create a new file if not exist
            3. `marker`: use `{mark}`, and it will be replaced with the value `marker_begin` and `marker_end`
            4. `marker_begin`: default `BEGIN`
            5. `marker_end`: default `END`
            6. `block`

            ```yaml
            blockinfile:
              path: "{{ hp_bashrc }}"
              create: yes
              marker: "# {mark} java configuration"
              block: |
                export JAVA_HOME={{ java_home }}
                export PATH=${JAVA_HOME}/bin:${PATH}
            ```
        8. `ansible.builtin.lineinfile`
        9. `ansible.builtin.user`
            1. `name`
            2. `password`
            3. `state`
                1. `absent`
                2. `present`
            4. `groups: "wheel"`
        10. `ansible.builtin.yum`
            1. `name`
                1. `postgresql`: a package name
                2. `postgresql-11.5`: a specific version of a package
            2. `state`
                1. `present`: ensure a package is installed
                2. `absent`: ensure a package is not installed
                3. `latest`: ensure the package is at the latest version

            ```yaml
            yum:
              name: "{{ packages }}"
              state: present
            ```
        11. `ansible.builtin.service`
            1. `name`
                1. `httpd`
                2. `postgresql`
            2. `state`
                1. `started`: ensure a service is started
                2. `restarted`: restart a service
                3. `stopped`: ensure a service is stopped
        12. `ansible.builtin.setup`: get raw system information, `ansible <hostname> -m ansible.builtin.setup`
        13. `ansible.builtin.set_fact`
        14. `ansible.builtin.debug`
            1. `var: ansible_facts`
            2. `msg: "the dirctory is empty"`
        15. `ansible.builtin.fail`
            1. `msg: ...`
    6. Tasks: the units of an action in ansible, can be executed once with an ad hoc command
    7. Roles

        automatically load related vars, file, tasks, handlers and other contents based on a known file structure. It can be easily reused and shared with other users

        1. File Structure

            have 8 main standard directories. By default, Ansible will look for a `main.yml` (`main.yaml`, `main`) in each directory within a role

            1. roles/
                1. common/
                    1. tasks/
                        1. main.yml: main tasks will be executed
                        2. other.yml
                    2. handlers/
                        1. main.yml: handlers, which may be used within or outside this role
                    3. library/
                        1. my_module.py: maybe used within this role
                    4. files/
                        1. main.yml: files that the role deploys
                    5. templates/
                        1. main.yml: templates that the role deploys
                    6. defaults/
                        1. main.yml: default varialbles for this role
                    7. vars/
                        1. main.yml: other variables for this role
                    8. meta/
                        1. main.yml: metadata for the role, including role dependencies
                2. webservers/
                    1. tasks/
                    2. defaults/
                    3. meta/
    8. Playbook: ordered lists of tasks, written in YAML, can be run repeatedly
        1. Keywords
            1. `name`
            2. `hosts: <pattern>`: a list of one or more host and groups patterns
                1. `all or *`: all hosts
                2. `ungroup`: hosts not in group children
                3. `host1`: one host
                4. `host1:host2`: multiple hosts using `:` or `,`. The comma is preferrred when dealing with ranges and IPv6
                5. `webserver`: one group
                6. `websever:dbserver`: multiple group
                7. `webserver:!dbserver`: hosts in webserver, excluding in dbserver
                8. `webserver:&dbserver`: hosts in webserver and dbserver
                9. `\*.example.com`: wildcard pattern
                10. `one*.com:dbservers`: mix wildcard patterns and groups
                11. `webserver[0], webserver[-1], webserver[0:2]`: use subscripts
                12. `~(web|db).*\.example\.com`: use regexp starting with `~`
            3. `remote_user`: user account for the SSH connection, can be defined per task
            4. `gather_facts: no`: disable ansible facts
            5. `become: yes`
            6. `become_method: [sudo, su]`
            7. `vars`: define variables in playbook
            8. `vars_files`: include variables defined in an external file
            9. `ignore_errors: true`
            10. `import_tasks`
            11. `include_tasks`
            12. `tasks`: the units of an action in ansible, can be executed once with an ad hoc command
                1. Keywords
                    1. `name:`
                    2. `import tasks`
                    3. `become: yes`
                    4. `the_module_name`
                    5. `register`: register a variable from the output of the task
                    6. `notify`
                    7. `ignore_errors: true`
                    8. `when`: conditional
                    9.  `vars`
                    10. `loop`
                    11. `until`
                    12. `retries: 5`: default 3, `until` must be defined, if not, `retries` is forced to 1
                    13. `delay: 10`: seconds, default is 5
            13. `handlers`

            ```yaml
            - hosts: webserver
              remote_user: username
              become: yes
              become_user: othername
              become_method: sudo | su
              vars:
                workdir: /var/lib/ansible
                logfile: /var/log/ansible-pull.log
              tasks:
                - name: test connection 
                  ping:
                  remote_user: username
            ```
4. Syntax
    1. Variable
        1. Naming: 
            1. only include letters, numbers and underscore
            2. cannot begin with numbers, can begin with underscore
            3. python keywords and playbook keywords are not valid
        2. Type
            1. simple variable: have a single value
                1. `remote_path: /opt/app_confg`
                2. `{{ remote_path}}`
                    1. use Jinja2 syntax to reference it
                    2. if start a value with `{{ foo}}`, quote the whole expression like `"{{foo}}"`, otherwise, the YAML parser may interpret it start of a YAML dictionary
            2. list: have multiple value
                1. `{{ region[0]}}`: bracket notation, recommended, always work
                2. `{{ region[1] }}`: dot notation, may collide with python dictionaries when
                    1. start and end with two underscores
                    2. any known public attributes

                ```yaml
                region:
                  - northeast
                  - southeast
                  - midwest
                ```
            3. dict: have data in key-value pairs
                1. `{{foo.field1}}`, `{{foo["field1"]}}`

                ```yaml
                foo:
                  field1: one
                  field2: two
                ```
        3. Builtin variables
            1. `ansible_version`

                ```yaml
                "ansible_version": {
                    "full": "2.11.1",
                    "major": 2,
                    "minor": 11,
                    "revision": 1,
                    "string": "2.11.1"
                }
                ```
            2. `ansible_facts`: remote server infomation, use `gather_facts: no` to disable it in playbook
                1. `{{ ansible_facts["nodename"] }}`: system hostname
            3. `hostvars`: host information in the play
                1. `{{ hostvars["asdf.example.com"]["ansible_facts"]["os_family"]}}`
                2. `{{ hostvars[item]["ansible_host"] }} {{ item }}`
            4. `groups`: all groups and related hosts
                1. `{{ groups["hp"] }}`

                ```yaml
                {% for host in groups['app_servers'] %}
                    {{ hostvars[host]['ansible_facts']['eth0']['ipv4']['address'] }}
                {% endfor %}
                ```
            5. `group_names`: a list of all the groups the current host is in

                ```yaml
                {% if 'webserver' in group_names %}
                    # some part of a configuration file that only applies to webservers
                {% endif %}
                ```
            6. `inventory_hostname`: the name of host configured in the inventory, an alternative to `ansible_hostname` when fact-gathering is disabled
            7. `inventory_hostname_short`: contain the part up to the first period, without the rest of the domain
            8. `inventory_dir`
            9. `inventory_file`: the pathname and the filename pointing to the Ansible’s inventory host file
            10. `ansible_play_hosts`: a list of all hosts still active in the current play
            11. `ansible_play_batch`
            12. `ansible_playbook_python`: the path to the python executable used to invoke the Ansible command line tool
            13. `playbook_dir`: the playbook base directory
            14. `role_path`: the current role’s pathname and only works inside a role
            15. `ansible_check_mode`: boolean, set to `True` if you run Ansible with `--check`
        4. Registering
            1. create variables from the output of an Ansible task with the keyword `register`
            2. host-level stored in memory, can be used in any later tasks in the play, cannot be be used for other play
            3. each module includes a `return` section about the return value for that module
            4. run playbook with `-v` to see the values for a particular task

            ```yaml
            - hosts: web_servers
              tasks:
                 - name: Run a shell command and register its output as a variable
                   ansible.builtin.shell: /usr/bin/foo
                   register: foo_result
                   ignore_errors: true

                 - name: Run a shell command using output of the previous task
                   ansible.builtin.shell: /usr/bin/bar
                   when: foo_result.rc == 5
            ```
        5. filtering
        6. defining
            1. in inventory
            2. in a playbook
            3. in included (external) files: using `vars_files` in the playbook
            4. at runtime: using `--extra-vars (-e)`, having the highest precedence
                1. key=value format: `ansible-playbook release.yml --extra-vars "version=1.23.45 other_variable=foo"`
                2. JSON format: `ansible-playbook arcade.yml --extra-vars '{"pacman":"mrs","ghosts":["inky","pinky","clyde","sue"]}'`
                3. from a JSON or YAML file using `@`: `ansible-playbook release.yml --extra-vars "@some_file.json"`
            
    2. Conditional
        1. `when`: a raw Jinja2 expression without double curly braces
            1. Operators
                1. `or, and`
                2. a list if multiple conditions need to be true
            2. examples
                1. `ansible_facts['distribution'] == "CentOS" and ansible_facts['distribution_major_version'] == "6"`
                2. `when: motd_contents.stdout.find('hi') != -1`
                3. `when: result is [faild, succeeded, skipped, defined, undefined]`
                4. `when: epic or monumental | bool`
        2. loops
            1. `loop`: require a list as input
                1. `item`: a list item
                2. `item.key`: a list of dict item, `loop: "{{ tag_data | dict2items }}` for a dict variable to be used in a loop
                3. `query`: return a list, `loop: {{ query("inventory_hostnames", "all")}}`
                4. when use `register` with loop, the register variable will contain a `results` attribute which is a list of all responses
                5. `loop.index`: current iteration of the loop, start from 1
                6. `loop.index0`: current iteration of the loop, start from 0
                7. `loop.length`: number of items in the sequence
                8. `loop.cycle("odd", "even")`: cycle between a list of sequences
            2. `until`
                1. retry a task until a certain condition is met
                2. a registered variable will include a key called `attempts` recording the number of the retries for the task

                ```yaml
                - name: Retry a task until a certain condition is met
                  ansible.builtin.shell: /usr/bin/foo
                  register: result
                  until: result.stdout.find("all systems go") != -1
                  retries: 5
                  delay: 10
                ```
5. Commands
    1. `ansible`
        1. Arguments
            1. `--version`
            2. `pattern`
            3. `-i | --inventory host-file`: can use multiple times
            4. `-m | --module-name moudule_name`: default `command` module
            5. `-a | --args "module options"`
            6. `-l | --limit pattern`: limits selected hosts to an additional pattern
            7. `--list-hosts`: output matching hosts, do not execute anything
            8. `--playbook-dir basedir`
            9. `-e | --extra-vars extra_vars`: see variable defining
            10. `-f | --forks forks`: number of parallel process to use, default 5
            11. `-u | --user remote_user`: specify remote user name, default using control node user
            12. `-b | --become`: runs operations with become with sudo power (without password prompting)
            13. `--become-user become_user`: runs operations as this user (default=root)
            14. `-K | --ask-become-pass`: asks for privilege escalation password
            15. `--ask-vault-pass`
            16. `--vault-password-file file_name`
            17. `--vault-id`
        2. Examples
            1. `ansible all -a "/bin/echo hello"`: execute command for all hosts
    2. `ansible-playbook`
        1. Arguments besides from `ansible`
            1. `playbook.yml`: specify a playbook file
            2. `--check`
            3. `--syntax-check`: performs a syntax check on the playbook, do not execute it
            4. `--list-tasks`
            5. `--list-hosts`
            6. `--verbose`
        2. Examples
            1. `ansible-playbook mytask.yaml`
    3. `ansible-lint`: test playbook syntax 
    4. `ansible-galaxy`
    5. `ansible-doc`:
        1. Arguments
            1. `-l`: list available modules
            2. `module_name`: docs for the module
        2. Examples
            1. `ansible-doc command`
    6. `ansible-vault`
        1. Arguments
            1. `--vault-id label@source`: specify a vault id and a source to obtain its password
            2. `create`: create a vault file using editor `$EDITOR` (default vi). The file will be saved as encrypted data
            3. `edit`: edit a vault file, decrypt it firstly
            4. `view`: view contents of an encrypted file without editing
            5. `rekey`: reset password
            6. `encrypt`: encrypt files
            7. `decrypt`
        2. Examples
            1. `ansible-vault create foo.yml`
            2. `ansible-vault encrypt foo.yml zoo.yml`
    7. `ansible-pull`

## Airlfow

1. Installation
    1. dependencies
        1. sqlite >= 3.15.0

            ```bash
            wget https://www.sqlite.org/2022/sqlite-autoconf-3380500.tar.gz --no-check-certificate
            ./configure && make && make install
            ```
    1. airflow

        ```bash
        AIRFLOW_VERSION=2.3.2
        PYTHON_VERSION=3.9
        CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
        pip install "apache-airflow[celery]==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
        ```
    2. dependent packages: `pip install "apache-airflow[pkg1, pkg2]==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"`
2. Configurations
    1. environments
        1. `export AIRFLOW_HOME=~/airflfow`
    2. initialization
        1. `airflow` generate busic project
        2. `airflow.cfg`
            1. [core]
                1. `executor = CeleryExecutor`
                2. `load_examples = True`
                3. `default_timezone = Asia/Shanghai`
            2. [database]
                1. sqlite: `sql_alchemy_conn = sqlite:////home/data/jr/airflow/airflow.db`
                2. mysql
                    1. create database

                        ```sql
                        CREATE DATABASE airflow_db CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
                        CREATE USER 'airflow_user' IDENTIFIED BY 'airflow_pass';
                        GRANT ALL PRIVILEGES ON airflow_db.* TO 'airflow_user';
                        ```
                    2. install mysqlclient through `apache-airflow[mysql]`: `pip install "apache-airflow[mysql]==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"`
                        1. may cause error `mysql_config not found`: `yum install mysql-devel`
                    3. sql_alchemy_conn: `mysql+mysqldb://<user>:<password>@<host>[:<port>]/<dbname>?charset=utf8`
                    4. sql_engine_collation_for_ids: `sql_engine_collation_for_ids=utf8mb3_bin` **default value** when database character set use `utf8mb4`
            3. [celery]
                1. redis: `pip install "apache-airflow[redis]==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"`
                    1. broker_url
                        1. redis
                            1. without password: `broker_url = redis://127.0.0.1:6379/15`
                            2. with passwd: `broker_url = redis://:password@127.0.0.1:6379/15`
                    2. result_backend
                        1. mysql: `result_backend = db+mysql://airflow:airflow@localhost/airflow?charset=utf8`
            4. [api]
                1. auth_backends
                    1. basic_auth: `auth_backends = airflow.api.auth.backend.basic_auth` 
            5. [webserver]
                1. timezone: `default_ui_timezone = Asia/Shanghai`
            6. [smtp]
                1. smtp_host 
                    1. tx: `smtp_host = smtp.exmail.qq.com`
                2. smtp_port: `smtp_port = 465`
                3. smtp_user: `smtp_user = hello@world.com`
                4. smtp_password: `smtp_password = password`
                5. smtp_mail_from: `smtp_mail_from = hello@world.com`
                6. smtp_ssl: `smtp_starttls = False; smtp_ssl = True; smtp_port = 465`
                7. smtp_starttls: `smtp_starttls = True; smtp_ssl = False; smtp_port = 587`
    3. operations
        1. db
            1. initialize: `airflow db init`
            2. upgrade: `airflow db upgrade`
        2. create user

            ```bash
            airflow users create \
                --username admin \
                --firstname Peter \
                --lastname Parker \
                --role Admin \
                --email spiderman@superhero.org
            ```
        3. webserver
            1. start: `airflow webserver -D`, default port `8080`
        4. scheduler
            1. start: `airflow scheduler -D`
        5. celery
            1. start: `airflow celery worker -D`
            2. stop: `airflow celery stop`
        6. flower
            1. start: `airflow celery flower -D`, default port `5555`

### Dependencies {-}

```python
def tables_in_query(sql_str):
    # remove the /* */ comments
    q = re.sub(r"/\*[^*]*\*+(?:[^*/][^*]*\*+)*/", "", sql_str)
    # remove whole line -- and # comments
    lines = [line for line in q.splitlines() if not re.match("^\s*(--|#)", line)]
    # remove trailing -- and # comments
    q = " ".join([re.split("--|#", line)[0] for line in lines])
    # split on blanks, parens and semicolons
    tokens = re.split(r"[\s)(;]+", q)

    # scan the tokens. if we see a FROM or JOIN, we set the get_next
    # flag, and grab the next one (unless it's SELECT).
    result = set()
    get_next = False
    for tok in tokens:
        if get_next:
            if tok.lower() not in ["", "select"]:
                result.add(tok)
            get_next = False
        get_next = tok.lower() in ["from", "join"]

    return result
```

```python
import sqlparse
from sqlparse.sql import IdentifierList, Identifier
from sqlparse.tokens import Keyword, DML

def is_subselect(parsed):
    if not parsed.is_group:
        return False
    for item in parsed.tokens:
        if item.ttype is DML and item.value.upper() == 'SELECT':
            return True
    return False


def extract_from_part(parsed):
    from_seen = False
    for item in parsed.tokens:
        if from_seen:
            if is_subselect(item):
                yield from extract_from_part(item)
            elif item.ttype is Keyword:
                return
            else:
                yield item
        elif item.ttype is Keyword and item.value.upper() == 'FROM':
            from_seen = True


def extract_table_identifiers(token_stream):
    for item in token_stream:
        if isinstance(item, IdentifierList):
            for identifier in item.get_identifiers():
                yield identifier.get_name()
        elif isinstance(item, Identifier):
            yield item.get_name()
        # It's a bug to check for Keyword here, but in the example
        # above some tables names are identified as keywords...
        elif item.ttype is Keyword:
            yield item.value


def extract_tables(sql):
    stream = extract_from_part(sqlparse.parse(sql)[0])
    return list(extract_table_identifiers(stream))


if __name__ == '__main__':
    sql = """
    select K.a,K.b from (select H.b from (select G.c from (select F.d from
    (select E.e from A, B, C, D, E), F), G), H), I, J, K order by 1,2;
    """

    tables = ', '.join(extract_tables(sql))
    print('Tables: {}'.format(tables))
```

#### Systemd {-}

Using systemd to deploy airflow server, and copy the following service file to `/usr/lib/systemd/system/`:

```sh
cp airflow-*er.service /usr/lib/systemd/system/
```

1. `airflow.conf` file

    ```
    D /run/airflow 0755 airflow airflow
    ```

    ```sh
    cp airflow.conf /etc/tmpfiles.d/
    mkdir /run/airflow
    chown airflow: /run/airflow
    ```

2. `airflow` file

    ```sh
    AIRFLOW_HOME=/server/proj/airflow/test
    SCHEDULER_RUNS=10
    LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib
    PYTHONPATH=${AIRFLOW_HOME}:${AIRFLOW_HOME}/plugins:${PYTHONPATH}
    PATH=/server/proj/.env/airflow/bin:/usr/bin:/user/local/bin:/usr/local/sbin:/usr/sbin:${PATH}
    ```

    ```sh
    cp airflow /etc/sysconfig/
    ```

3. `airflow-webserver.service` file
   
    ```ini
    [Unit]
    Description=Airflow webserver daemon 
    After=network.target postgresql.service redis.service
    Wants=postgresql.service redis.service

    [Service]
    EnvironmentFile=/etc/sysconfig/airflow
    User=airflow
    Group=airflow
    Type=simple
    ExecStart=/server/proj/.env/airflow/bin/airflow webserver -p 8000 --pid /run/airflow/webserver.pid
    Restart=on-failure
    RestartSec=5s
    PrivateTmp=true

    [Install]
    WantedBy=multi-user.target
    ```

4. `airflow-worker.service` file

    ```ini
    [Unit]
    Description=Airflow celery worker daemon
    After=network.target postgresql.service redis.service
    Wants=postgresql.service redis.service

    [Service]
    EnvironmentFile=/etc/sysconfig/airflow
    User=airflow
    Group=airflow
    Type=simple
    ExecStart=/server/proj/.env/airflow/bin/airflow worker
    Restart=on-failure
    RestartSec=10s

    [Install]
    WantedBy=multi-user.target
    ```

5. `airflow-scheduler.service` file

    ```ini
    [Unit]
    Description=Airflow scheduler daemon
    After=network.target postgresql.service redis.service
    Wants=postgresql.service redis.service

    [Service]
    EnvironmentFile=/etc/sysconfig/airflow
    User=airflow
    Group=airflow
    Type=simple
    ExecStart=/server/proj/.env/airflow/bin/airflow scheduler
    Restart=always
    RestartSec=5s

    [Install]
    WantedBy=multi-user.target
    ```

6. `airflow-flower.service` file 

    ```ini
    [Unit]
    Description=Airflow celery flower
    After=network.target postgresql.service redis.service
    Wants=postgresql.service redis.service

    [Service]
    EnvironmentFile=/etc/sysconfig/airflow
    User=airflow
    Group=airflow
    Type=simple
    ExecStart=/server/proj/.env/airflow/bin/airflow flower
    Restart=on-failure
    RestartSec=5s

    [Install]
    WantedBy=multi-user.target
    ```

### Concepts {-}

1. DAG: `from airflow import DAG`

    DAGs are defined in standard python files placed in Airflow's `DAG_FOLDER` directory. Airflow will execute the code in each file recursively to build the DAG objects dynamically.

    ```python
    # tutorial.py
    from airflow import DAG
    from datetime import datetime, timedelta
    
    default_args = {
        "owner": "airflow",
        "depends_on_past": False,
        "start_date": datatime(2020, 3, 15),
        "email": ["airflow@example.com],
        "email_on_failure": True,
        "email_on_retry": False,
        "retries": 2,
        "retry_delay": timedelta(minutes=5),
    }
    
    dag = DAG("tutorial", default_args = default_args, schedule_interval = "10 * * * *")
    
    # Since `1.8`, DAGs can be used as context managers to automatically assign new operators to that DAG.
    with DAG("tutorial", default_args=default_args) as dag:
        op = DummyOperator("op")
    
    op.dag is dag # True
    ```

    1. Parameters
        1. `dag_id = "tutorial"`: `str`, the id of the DAG
        2. `description = "..."`: `str`, the description for the DAG to be shown on the webserver 
        3. `schedule_interval` defines when to run the dag.
            1. `"* * * * *"`: similar to cron format
            2. `datetime.timedelta`
            3. preset cron
                1. `None`: don't schedule, use for exclusively "externally triggered" DAGs
                2. `@once`: schedule once and only once
                3. `@hourly`: run once an hour at the beginning of the hour, `0 * * * *`
                4. `@daily`: run once a day at midnight, `0 0 * * * `
                5. `@weekly`: run once a week at midnight on **Sunday** morning, `0 0 * * 0`
                6. `@monthly`: run once a month at midnight of the first day of the month, `0 0 1 * *`
                7. `@yearly`: run once a year at midnight of January 1, `0 0 1 1 *`
        4. `start_date`
        5. `end_date`: optional
        6. `catchup = False`: `bool`, when `False`, the scheduler will only create a DAG Run for the most current instance of the DAG interval series, not all for any interval that has not been run or has been cleared
        7. `dagrun_timeout`: `datetime.timedelta`, specify how long a DagRun should be up before timeout / failing, so that new DagRuns can be created
        8. `parallelism`: global configuration `parallelism` in `airflow.cfg`, how many tasks to run for every airflow worker
        9.  `concurrency = 10`: `int`, the number of task instances allowed to run concurrently per DAG, read `dag_concurrency` from `airflow.cfg` if not set
        10. `max_active_runs = 5`: `int`, maximum number of active DAG runs per DAG, read `max_active_runs_per_dag` from `airflow.cfg` if not set, beyond this number, the scheduler won’t create new active DAG runs. e.g., when using `backfill`, or manually trigger the dag, the running number dag will be controlled no more than this value. `max_active_runs = 1` will make sure the same DAG running sequencically, one after another, the later one will not start before the previous one successes
        11. `default_args`: apply common parameters to any of its operators
            * `"owner": "airflow"`: `str`, the owner of the task, using the unix username is recommended
            * `"start_date": datetime(2020, 3, 15)`: `datetime`, the **execution date** start date, determine the first task instance
            * `"end_date": datetime(2020, 3, 20)`: `datetime`, if specified, the scheduler won't go beyond this date
            * `"email": ["airflow@example.com"]`
            * `"email_on_failure": True`: `bool`, send mail when task fails
            * `"email_on_retry: True`: `bool`, whether retries when the task fails
            * `"retries": 5`: `int`, how many times to retry before failing the task
            * `"retry_delay": timedelta(minutes=5)`: `datetime.timedelta`, when to retry if task fails
            * `"trigger_rule": "all_success"`: `str`, default `all_success`,  parent dependencies are applied for the task to get triggered
                * all_success
                * all_failed
                * all_done
                * one_success
                * one_failed
                * dummy
            * `"execution_timeout": timedelta(hours=3)`: `datetime.timedelta`, max time allowed for the task instance execution, if it goes beyond it will raise and fail
            * `"depends_on_past": False"`: `bool`, when `true`, task instances will run sequentially relying on previous task’s schedule to success. The task instance for the `start_date` is allowed to run
            * `"wait_for_downstream: False"`: `bool`, when `true`, an instance of task X will wait for **tasks immediately downstream of the previous instance of task X to finish**, useful when different instances of X run, `depends_on_past` will be forced to `True`
            * `"priority_weight": 10`: `int`, priority weight of this task against other task, allowing the executor to trigger higher priority tasks before others when things get backed up
            * `"pool": "backfill"`: `str`, default `"default pool"`, which pool tasks belong to, limit concurrrency for certain tasks
            * `"queue": "bash_queue"`: `str`, tasks belong to which queue, CeleryExecutor support it
            * `"task_concurrency": 10`: `int`, when set, a task will be able to limit the concurrent runs across execution_dates
            * `"on_failure_callback"`: `callable`
            * `"on_success_callback"`: `callble`
            * `"on_retry_callback"`: `callble`
    
    2. Operations
        1. Shell
            1. `python tutorial.py`: test whether the dag pipeline parses
            2. `airflow list_dags`: print the list of **active** dags
            3. `airflow list_tasks tutorial`: print the list of tasks in the dag_id tutorial
            4. `airflow list_tasks tutorial --tree`: print the hierarchy of tasks in the dag_id tutorial
        2. methods
            1. `.has_task(task_id)`
            2. `.get_task(task_id)`
            3. `.add_task(task)`
            4. `.add_tasks(tasks)`

2. Operators:
    1. Parameters, additional besides the `default_args` in dag, `task_id` and `owner` are necessary
        1. `task_id = "a task"`:  `str`, a unique, meaning id for the task, first argument for every operator
        2. `owner = "airflow"`
        3. `dag = "dag_id"`: which DAG this task belong to
        4. `resources = {"cpus": 8, "ram": 1024, "disk": 1024, "gpus": 8}`: MB unit for ram and disk
    2. Tasks
        1. task is instanced operators
        2. task instance is a task and has been assign to a DAG and has a state with a DAG:
            * success
            * running
            * failed
            * skipped
            * retry
            * queued
            * no status
    3. Operations
        1. dependencies
            1. t1 before t2
                1. `t2.set_upstream(t1)`
                2. `dag.set_dependency("task_id_t1", "task_id_t2")`
                3. `t1 >> t1 (since 1.8)`
            2. t1 after t2
                1. `t1.set_downstream(t2)`
                2. `t1 << t2 (since 1.8)`
        2. shell
            1. `airflow test`: testing a single task instance at a specific `execute_date` locally, simulate the scheduler running task or dag at a specific date + time, output log to stdout, do not bother with dependencies and do not communicate state to database
                1. `airflow test tutorial print_date 2015-06-01`: test `print_date` on execution_date `2015-06-01`
            2. `airflow run`: similar to `airflow test`, but run as actual task
                1. `airflow run tutorial print_date 2015-01-01`
            3. `airflow backfill` 
                1. `airflow backfill tutorial -s 2015-06-01 -e 2015-06-07`
    4. Operators
        1. `DummyOperator`: `airflow.operators.dummy_operator import DummyOperator`
        2. `BashOperator`: `airflow.operators.bash_operator import BashOperator`
            1. `bash_command`: shell statements or a `.sh` file or Jinja template, file location relative to the directory containing the pipeline file
            2. `params={"my_param": "parameter I passed in"}`: pass a dict parameters to templates
              ```python
                t1 = BashOperator(
                    task_id="print_hello",
                    bash_command="date",
                    dag=dag
                    )
            
                templated_command = """
                    {% for i in range(5) %}
                        echo "{{ ds }}"
                        echo "{{ macros.ds_add(ds, 7) }}"
                        echo "{{ params.my_param }}"
                    {% endfor %}
                    """
            
                t2 = BashOperator(
                    task_id='templated',
                    bash_command=templated_command,
                    params={'my_param': 'Parameter I passed in'},
                    dag=dag)
                
                t2.set_upstream(t1)
                ```

        3. `PythonOperator`: `airflow.operators.python_operator import PythonOperator`
        4. `EmailOperator`: `airflow.operators.email_operator import EmailOperator`
        5. `SubDagOperator`: `airflow.operators.subdag_operator import SubDagOperator`
        6. `SSHOperator`: `from airflow.contrib.operators.ssh_operator import SSHOperator`
        7. Database:
            1. `SqliteOperator`: `from airflow.operators.sqlite_operator import SqliteOperator`
            2. `PostgresOperator`: `from airflow.operators.postgres_operator import PostgresOperator`
            3. `MySqlOperator`: `airflow.operators.mysql_operator import MySqlOperator`
            4. `MsSqlOperator`: `from airflow.operators.mssql_operator import MsSqlOperator`
            5. `OracleOperator`: `from airflow.operators.oracle_operator import OracleOperator`
            6. `JdbcOperator`: `from airflow.operators.jdbc_operator import JdbcOperator`
            7. `HiveOperator`: `from airflow.operators.hive_operator import HiveOperator`
        8. `Sensor`: wait for a certain time, file, database row, etc...
3. Default Variables: Airflow engine passes a few variables by default that are accessible in all templates:
    1. `{{ ds }}`: the execution date as `YYYY-MM-DD`
    2. `{{ ds_nodash }}`: the execution date as `YYYYMMDD`
    3. `{{ execution_date }}`: the execution_date, (datetime.datetime)
    4. `{{ dag}}`: the DAG object
    5. `{{ task }}`: the Task object, `{{ task.owner}}`, `{{ task.task_id}}`, ...
    6. `{{ task_instance }}, {{ ti }}`: the task_instance object, `{{ ti.hostname}}`
    7. `{{ task_instance_key_str }}`: a unique, human-readable key to task instance formatted `{dag_id}_{task_id}_{ds}`
    8. `{{ params }}`: a reference to the user_defined params dictionary
    9. `{{ conf }}`: the full configuration object located at `airflow.configuration.conf` which represents the content of your `airflow.cfg`
    10. `{{ var.value.my_var }}`: global defined variables represented as a dictionary
    11. `{{ var.json.my_var.path }}`: global defined variables represented as a dictionary with deserialized JSON object, append the path to the key within the     JSON object
    12. `{{ run_id }}`: the `run_id` of the current DAG run
    13. `{{ dag_run }}`: a reference to the DagRun object
    14. `{{ test_mode }}`: whether the task instance was called using the CLI’s `test` subcommand
4. Macros
    1. `macros.datetime`: The standard lib’s `datetime.datetime`
    2. `macros.timedelta`: The standard lib’s `datetime.timedelta`
    3. `macros.dateutil`: A reference to the `dateutil` package
    4. `macros.time`: The standard lib’s `time`
    5. `macros.uuid`: The standard lib’s `uuid`
    6. `macros.random`: The standard lib’s `random`

5. Pools

    Airflow pools can be used to limit the execution parallelism on arbitrary sets of tasks. The list of pools is managed in the UI (`Menu -> Admin -> Pools`) by giving the pools a name and assigning it a number of worker slots. The `pool` parameter can be used in conjunction with `priority_weight` to define priorities in the queue, and which tasks get executed first as slots open up in the pool. The default `priority_weight` is 1, and can be bumped to any number. When sorting the queue to evaluate which task should be executed next, Airflow use the `priority_weight`, summed up with all of the `priority_weight` values from tasks downstream from this task. You can use this to bump a specific important task and the whole path to that task gets prioritized accordingly.

6. Queues

    When using `CeleryExecutor`, the celery queues that tasks are sent to can be specified. `queue` is an attribute of BaseOperator, so any task can be assigned to any queue. The default queue for the environment is defined in the `airflow.cfg`'s `celery -> default_queue`. This defines the queue that tasks get assigned to when not specified, as well as which queue Airflow workers listen to when started.

    Workers can listen to one or multiple queues of tasks. When a worker is started (using the command `airflow worker`), a set of comma delimited queue names can be specified (e.g. `airflow worker -q spark`). This worker will then only pick up tasks wired to the specified queue(s).

7. Connections

    The connection information to external systems is stored in the Airflow metadata database and managed in the UI (`Menu -> Admin -> Connections`). A `conn_id` is defined there and `hostname / login / password / schema(database)` information attached to it. Airflow pipelines can simply refer to the centrally managed `conn_id` without having to hard code any of this information anywhere.

    Many connections with the same `conn_id` can be defined and when that is the case, and when the hooks uses the `get_connection` method from `BaseHook`, Airflow will choose one connection randomly, allowing for some basic load balancing and fault tolerance when used in conjunction with retries.

    Airflow also has the ability to reference connections via environment variables from the operating system. The environment variable needs to be prefixed with `AIRFLOW_CONN_` to be considered a connection. When referencing the connection in the Airflow pipeline, the `conn_id` should be the name of the variable without the prefix. For example, if the `conn_id is` named `postgres_master` the environment variable should be named `AIRFLOW_CONN_POSTGRES_MASTER` (note that the environment variable must be all uppercase). Airflow assumes the value returned from the environment variable to be in a URI format (e.g. `postgres://user:password@localhost:5432/master` or `s3://accesskey:secretkey@S3`).

    `airflow connections` operations:

    1. `-l, --list`
    1. `-a, --add`
    2. `-d, delete`
    3. `--conn_id`: required to add or delete a connection, use lowercase characters and separated words with underscores `_`
    4. `--conn_type`: required to add a connection without conn_uri
    5. `--conn_host`
    1. `--conn_port`
    2. `--conn_schema`: specify database name
    3. `--conn_login`: login user
    4.  `--conn_password`
    5.  `conn_extra`: Extra field as json dictionary, optional when adding a connection, e.g. `{"charset": "utf8"}` for MySQL
    1.  `--conn_uri`: required to add a connection without conn_type

    ```sh
    # add a connection
    airflow connections -a --conn_id prd --conn_type 'postgres' --conn_host '127.0.0.1' --conn_port 5432 --conn_schema postgres --conn_login postgres --conn_password 1234
    ```

    ```python
    from airflow.hooks.base_hook import BaseHook

    conn = BaseHook.get_connection("conn_id")
    conn.conn_id
    conn.conn_type
    conn.host
    conn.port
    conn.schema
    conn.login
    conn.passowrd
    conn.extra
    conn.get_extra()
    conn.get_url()
    conn.extra_dejson.get('charset', False)
    ```

8. Hooks

    Hooks are interfaces to external platforms and databases like Hive, Postgres, HDFS. They also use `airflow.models.Connection` model to retrieve hostnames and authentication information. Hooks keep authentication code and information out of pipelines, centralized in the metadata database.

    ```python
    from airflow.hooks.postgres_hook import PostgresHook
    pg = PostgresHook("prd_gp")
    conn = pg.get_conn() # get a connection to the database
    curr = conn.cursor()
    ...
    ```

9. Xcoms
10. Variables

    Variables are a generic way to store and retrieve arbitrary content or settings as a simple key value stored within Airflow. Variables can be listed, created, updated and deleted from the UI (`Admin -> Variables`), code or CLI. While your pipeline code definition and most of your constants and variables should be defined in code and stored in source control, it can be useful to have some variables or configuration items accessible and modifiable through the UI.

    ```python
    from airflow.models import Variable
    foo = Variable.get("foo")
    bar = Variable.get("bar", deserialize_json=True) # json content and will be deserialized into bar
    ```

    `airflow variables`:

    1. `-s, --set`
    2. `-g, --get`
    3. `-x, --delete`: delete a variable
    4. `-i, --import`: import variables from JSON file
    5. `-e, --export`: export variables to JSON file
    6. `-d, --default`: default value returned if variable do not exist



## Packages {#py-pkgs}

### re {-#py-re}

1. Mode
    1. `re.I. re.IGNORECASE`: make case-insensitive
    2. `re.M, re.MULTILINE`
    3. `re.S, re.DOTALL`: make `.` match every character plus the newline
    4. `re.A, re.ASCII`: make `\d, \D,\w, \W, \s, \S, \b, \B` dependent on ASCII, not Unicode
    5. `re.L, re.LOCALE`: make `\w, \W, \b, \B` and case sensitive dependent on the current locale, not recommended
    6. `re.U, re.UNICODE`: default, make `\d, \D,\w, \W, \s, \S, \b, \B` dependent on Unicode character properties
    7. `re.X, re.VERBOSE`
    8. use `|` to set multiple mode, `re.I | re.M`
2. Metacharacters
    1. `^`: match the beginning of string, when in `re.MULTILINE` mode, match immediately after each newline
    2. `$`: match the end of string or just before the newline at the end of the string, when in `re.MULTILINE` mode, match immediately before each newline
    3. `.`: match any character excpet newline, when in `re.S` mode, include the newline
    4. `[]`: match any character within it, metacharacters are not active inside it
        1. `-`: when between two characters, mean a range characters from start to end, `[a-z]` means from a to z, when at the start of `[` or end of `]`, just means `-` character, `[-az]`, `[az-]` means `-` or `a` or `z`
        2. `^`: when at the start of `[]`, means negation. `[^a-z]` means any other characters except `[a-z]`, other position has no special meaning, just means `^` character
        3. `]`: using `[]...]` to include `]` character
        4. `[`: `[...[...]`: put `[` at any position in `[]`, be care when `[` in front of `-`, `[[-a]` means character from `[` to `a`, not mean `[` or `-` or `a`
    5. `*`: greedy repeat 0 to any times
    6. `+`: greedy repeat 1 to any times
    7. `?`: greedy repeat 0 or 1 times
    8. `{m, n},, {n}, {n, }, {, n}`: greedy repeat between m and n times, n times, or no less or no more than n times 
    9.  `|`: alternation, match any part of it, `abc|ABC` matches `abc` or `ABC`
    10. `\\`: match a literal backslash `\`
    11. `()`: numbered subgroup
3. Extensions
    1.  `*?,+?,??,{m, n}?`: non-greedy repeat
    2.  `(?P<name>...)`: Python's specific named subgroup, the substring matched by the group is accessible by name.
    3.  `\number, \1, \2, ..., (?P=name)`: back reference the subgroup, in `re.sub()`, use `\1, \g<1>, \g<hours>`
    4.  `(?aiLmsux)`: set `A, I, L, M, S, U, or X` flag for the RE, embed in the front of pattern, instead of a flag argument
    5.  `(?:...)`: non-grouping version of regular parentheses.
    6.  `(?#...)`: a comment, ignored.
    7.  `(?=...)`: positive lookahead assertion, match if ... matches next, but doesn't consume the string.
    8.  `(?!...)`: negative lookahead assertion, match if ... doesn't match next.
    9.  `(?<=...)`: positive lookbehind assertion, match if preceded by ... (must be fixed length).
    10. `(?<!...)`: negative lookbehind assertion, match if not preceded by ... (must be fixed length).
    11. `(?(id/name)yes-pattern|no-pattern)` match yes-pattern if the group id/name matched, or no-pattern if the group not matched, no-pattern can be omitted
4. Predefined Character Classes
    1. `\A`: match only at the start of the string.
    2. `\Z`: match only at the end of the string.
    3. `\d`: `[0-9]`, match any decimal digit, In string patterns without the ASCII flag, it will match the whole range of Unicode digits
    4. `\D`: `[^\d]`, match complement of `\d`
    5. `\s`: `[ \t\n\r\f\v]`, match any whitespace character
    6. `\S`: `[^ \t\n\r\f\v]`, match complement of `\s`
    7. `\w`: `[a-zA-Z0-9_]`, match any alphanumeric character; with LOCALE, it will match the set `[a-zA-Z0-9_]` plus characters defined as letters for the current locale.
    8. `\W`: match complement of `\w`.
    9.  `\b`: match the empty string, but only at the start or end of a word.
    10. `\B`: match the empty string, but not at the start or end of a word
5. Functions
    1. `re.compile(pattern, flags)`: compile pattern first, for use the same pattern more than once
    2. `re.match(pattern, string, flags)`: return Match object or None, match pattern only at the beginning of string, not work for MULTILINE mode
    3. `re.fullmatch()`: return Match object or None, match pattern to the entire string
    4. `re.search()`: return Match object or None, return the first found substring
    5. `re.findall()`: return a list of all non-overlapping matches in the string
    6. `re.finditer()`: return an iterator Match object
    7. `re.split()`: return a list of splited substrings, **when the pattern is grouped, the group also returned**
    8. `re.sub()`: return the replacement string
    9. `re.subn()`: return `(new_string, number)`
    10. `re.escape()`: escape all the characters in pattern except ASCII `\w`, useful for matching an arbitrary literal string that may have regular expression metacharacters in it. It must not be used for replacement string in `re.sub()` and `re.subn()`
    11. `re.purge()`: clear the regular expression caches
6. `re.Match` Object
    1. `.group(group=0), .group(1,3,5)`: return subgroup by indices or name, for 0 return the entire match
    2. `.groups()`: return a tuple containing all the subgroups of the match from 1
    3. `.start(group=0)`: return the start of subgroup
    4. `.end(group=0)`: return the end of subgroup
    5. `.span(group=0)`: return `(m.start(group), m.end(group))`
    6. `.groupdict()`: return named group as a dict
    7. `.expand()`: return string obtained by doing backslash substitution on the template string, `.expand("hello\1\g<name>")`
    8.  `.regs()`: return a tuple of span of entire group and subgroup
    9. `.pos`: from which postition start to look for a match
    10. `.endpos`: from which position not to go
    11. `.lastindex`: the integer index of the last matched capturing group
    12. `.lastgroup`: the name of the last matched capturing group
    13. `.re`: return the pattern to match
    14. `.string`: return the string to be matched
7. Notes
    1. use `r"pattern"` to specify pattern

### logging {-}

```python
import logging

# basiConfig
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format="%(asctime)s %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
logging.info("start running")

# logger name config: spam_application
logger = logging.getLogger("spam_application")
logger.setLevel(logging.DEBUG)

fh = logging.FileHandler("spam.log", "w")
fh.setLevel(logging.DEBUG)

ch = logging.StreamHandler()
ch.setLevel(logging.ERROR)

formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s", "%Y-%m-%d %H:%M:%S")

fh.setFormatter(formatter)
ch.setFormatter(formatter)

logger.addHandler(fh)
logger.addHandler(ch)

logger.info("start running")
```

References:

1. [howto-logging-tutorial](`https://docs.python.org/3/howto/logging.html#logging-advanced-tutorial`)
2. [howto-logging-cookbook](https://docs.python.org/3/howto/logging-cookbook.html)
3. [python-logging](https://realpython.com/python-logging/)
4. [python-logging-source-code](https://realpython.com/python-logging-source-code/)
5. [python-factory-method](https://realpython.com/factory-method-python/)
6. [python-threading](https://realpython.com/intro-to-python-threading)
7. [python-modules-packages](https://realpython.com/python-modules-packages/)
8. [python-variables](https://realpython.com/python-variables/)
   
#### logger functions {-}

1. `logger.debug()`
2. `logger.info()`
3. `logger.warning()`
4. `logger.error()`
5. `logger.fatal()`
6. `logger.exception() <=> logger.error(exc_info = True)`
7. `logging.basiConfig()`
8. `logger.getLogger(__name__)`: using module-level `__name__` as the name parameter to `getLogger()` to create a logger object
9. `logger.setLevel(logging.INFO)`
10. `logger.addHandler(hdl)`
11. `logger.removeHandler(hdl)`

#### Levels {-}

1. CRITICAL(FATAL): 50
2. ERROR: 40
3. WARNING(WARN): default, 30
4. INFO: 20
5. DEBUG: 10
6. NOTSET: 0

#### Handlers {-}

1. handlers type
    * `FileHandler`
        1. `filename`
        2. `mode`:
            1. `a`: default, append to the end of file
            2. `w`: overwrite the original file
    * `StreamHandler`
2. `handler.setLevel(logging.INFO)`
3. `handler.setFormatter(formatter)`

#### Formatter {-}

1. `fmt`
    1. `%(asctime)s`: textual time when logrecord created
    2. `%(name)s`: logger name, default `root`
    3. `%(levelname)s`
    4. `%(levelno)s`
    5. `%(message)s`
2. `datefmt`: `"%Y-%m-%d %H:%M:%S"`


### http.server {-}

```sh
python -m http.server 8888
```

### pytz {-}

```python
import pytz
import datetime

TZ = pytz.timezone("Asia/Shanghai")
NOW = datetime.datetime.now(TZ)
NOW_DATE = NOW.strftime("%Y-%m-%d")
```

### pillow {-}

see [pillow](https://pillow.readthedocs.io/en/latest/index.html)

```python
from PIL import Image
import imageio

im = Image.open("ll.gif")
try:
    i = 0
    while True:
        im.seek(i)
        im.save("{}.png".format(i))
        i = i + 1
except:
    pass

images = []

for j in range(i):
    images.append(imageio.imread("{}.png".format(j)))
 
imageio.mimwrite("ll-out.gif", images, "GIF", duration=0.3)
```

### numpy {-}

1. Constants
    1. `np.pi`
    2. `np.e`
    3. `np.nan`: `log(-10)`
    4. `np.inf`
    5. `np.PINF`: postive infinity
    6. `np.NINF`: negative infinity, `log(0)`
    7. `np.newaxis`: `None`
2. Ndarray Types
    1. `np.bool`
    2. `np.int16`
    3. `np.int32`
    4. `np.int64`: default
    5. `np.float32`
    6. `np.float64`: default
    7. `np.coomplex`
3. Initialization
    1. `np.array([3, 4, 5], dtype=np.int64)`
    2. `np.arange(15).reshape(3, 5)`
    3. `np.zeros((3, 4), dtype=np.int16); np.zeros_like(a)`
    4. `np.ones((3, 4)); np.ones_like(a)`
    5. `np.empty((2, 3)); np.empty_like(a)`: uninitialized
    6. `np.linspace(0, 2, 9)`: `[0, .25, .5, ..., 2]`
    7. `np.fromfunction(f, shape, dtype)`
4. Attributes
    1. `.ndim`: axes (dimensions) number
    2. `.shape`: dimensions
    3. `.size`: elements number
    4. `.dtype`: element type
    5. `.itemsize` element memory size of bytes
5. Methods
    1. `.sum()`
    2. `.cumsum(axis=1)`
    3. `.min()`
    4. `.max()`
    5. `.reshape()`
6. Slicing
    1. `x[1:10] = x[1:10, :]`: the first axis array
7. Operators
    1. `+ - * /`
    2. `+= *=`: modify an existing array rather than create a new one
8. Functions
    1. `np.concatenate()`
    2. `np.diag()`
    3. `np.sum()`
    4. `lnp.sin()`
    5. `np.cos()`
    6. `np.exp()`
    7. `np.log()`
    8. `np.log2()`
    9. `np.dot(); @`
    10. `np.linalg.inv()`
9. References
    1. [numpy](https://numpy.org/devdocs/reference/index.html#reference)

### pandas {-}

1. `pd.DataFrame`

### Sklearn {-}

1. Dataset: `from sklearn import dataset`
    1. `load_iris`
    2. `load_diabetes`
2. Preprocessing: `from sklearn import preprocessing`
    1. `StandardScaler()`
3. Metric: `from sklearn import metric`
    1. `mean_square_error`
    2. `r2_score`
    3. `accuracy_score`
4. Model Selection: `from sklearn import model_selection`
    1. `train_test_split()`
5. Pipeline: `from sklearn.pipeline import make_pipeline`
    1. `make_pipeline()`
6. Ensemble: `from sklearn import ensemble`
    1. `RandomForestRegressor`
    2. `GradientBoostingRegressor`
    3. `VotingRegressor`
7. Linear Model:
    1. Models: `from sklearn import linear_model`
        1. `LinearRegression`
        2. `Ridge`
        3. `LogisticRegression`
    2. Methods:
        1. `fit()`
        2. `predict()`
    3. Attributes
        1. `coef_`
        2. `intercept`
    4. Examples

        ```python
        reg = linear_model.LinearRegression()
        reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])
        reg.coef_ 
        ```

### Matplotlib {-}

1. `matplotlib.pyplot`
    1. Geoms
        1. `plot`
        2. `scatter`
    2. Parameters
        1. color
        2. linewidth
    3.  Themes
        1. title
        2. xlabel
        3. ylabel
        4. legend
        5. xtics
        6. yticks

### Seaborn {-}

1. Font

    ```python
    import seaborn as sns
    sns.set_style(None, {"font.sans-serif":["SimHei", "Arial"]})
    ```

2. Geoms
    1. `sns.barplot()`
    2. `sns.lineplot()`
    3. `sns.scatterplot()`
    4. `sns.histplot()`
    5. `sns.displot()`
    6. `sns.lmplot()`: scatter plot with linear model
    7. `sns.relplot()`: relationships visualization
3. Style
    1. hue
    2. style
    3. size
4. Theme
    1. `ax.set_xlabel(r"$y$", size = 16) `
    2. `ax.set_ylabel(r"$\hat{y}$", size = 16, rotation = 0, labelpad = 15) `
    3. `ax.set_title(r"$y$ vs. $\hat{y}$", size = 16, pad = 10)`
5. Example

    ```python
    import seaborn as sns
    import matplotlib.pyplot as plt

    fig, ax = plt.subplots() 
    sns.scatterplot(model.y, model.y_hat) 
    ax.set_xlabel(r"$y$", size = 16) 
    ax.set_ylabel(r"$\hat{y}$", size = 16, rotation = 0, labelpad = 15) 
    ax.set_title(r"$y$ vs. $\hat{y}$", size = 16, pad = 10)
    ```

### networkx {-}

```python
import networkx as nx
```

* Graphs
    * Common
        * `G.graph`: get graph attributes
        * `G.graph["day"] = "Monday"`: graph attributes setting
        * `G.clear()`: remove all nodes and edges
    * Undirected
        * `G = nx.Graph()`: graph without direction
        * `G = nx.Graph(day="Friday", ...)"`: graph with attributes
        * `G = nx.Graph(edgelist)`
        * `H = nx.path_graph(10)`
    * Directed
        * `DG = nx.Digraph(); DG = nx.Digraph(day="Friday"); DG = nx.Digraph(G)`
        * `DG.out_edges`
        * `DG.in_degree`
        * `DG.out_degree; DG.out_degree(1, weight="weight")`
        * `DG.predecessors(1)`
        * `DG.successors(1)`
        * `DG.to_undirected()`
    * Multigraphs: allow multiple edges between any pair of nodes 
        * `MG = nx.MultiGraph()`
        * `MG = nx.MultiDiGraph()`
    * Analyzing
        * `nx.connected_components(G)`
        * `nx.clustring(G)`
    * Drawing
* Nodes: can be any **hashable** objects, except `None`
    * `G.add_node(1); G.add_node(2, color="red")`
    * `G.add_node(H)`: use graph as a node, allow graphs of graphs
    * `G.add_nodes_from([2,3])`: add nodes from iterable container
    * `G.add_nodes_from((node, node_attributes_dict))`: add nodes with attributes
    * `G.add_nodes_from(H)`: incorporate nodes from other graph
    * `G.remove_node(2)`
    * `G.remove_nodes_from([2, 3])`
    * `G.nodes`
    * `G.nodes[1]; G.nodes[1]["room"] = 714`: node 1 attributes
    * `g.nodes.data()`: nodes attributes
    * `G.number_of_nodes()`
* Edges
    * `G.add_edge(2, 3)`: add an edge from 2 to 3
    * `G.add_edge(2, 3, weight = 3.14)`: add an edge with attributes
    * `G.add_edges_from([(1, 2), (1, 3)])`: add a list of edges
    * `G.add_edges_from(H.edges)`
    * `G.add_weighted_edges_from([(1, 2, 0.125), (1, 3, 0.75)])`
    * `G.remove_edge(2, 3)`
    * `G.remove_edges_from([(1, 2), (1, 3)])`
    * `G.number_of_edges()`
    * `G.edges; G.edges[1, 2]; G.edges[1, 2]["color"] = "red"`
    * `G.degree(); G.degree([1, 2]); G.degree[1]`: degree of node 1, number of adj edges
    * `G.adj[1]; G[1]; G[1][2]`: neighbors of node 1
    * `G.adjacency(); G.adj.items()`: all nodes adjacency pairs
    * `G.edges.data(); G.edges.data("weight")`

## skills {#py-skills}

1. `del _cache[next(iter(_cache))]`: delete the first dict key
