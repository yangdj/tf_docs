# Linear Regression

## Assumptions

1. Response is a linear function of predictors
2. Errors are unrelated to predictors
3. Errors have zero mean and constant variance 
    1. Standardized residuals can assess unusual values and test independency and variance.
    2. It can be plotted against each of the explanatory variables that are included in the model, and plotted against the Ô¨Åtted values \(\hat y_i\) to test whether they have  constant variance (homoscedasticity).
4. Errors have normal distribution
    1. Normal probability plot can assess normality. In the plot the points should lie on or near a straight line, otherwise indicating a departure from this distribution.

## Estimation

1. OLS

    $$
    \begin{aligned}
    &\min_{\beta} ||y - X\beta||_2^2 \quad \beta = (\beta_0, \beta_1, \dots, \beta_p) \\
    &\hat{\beta} = (X^TX)^{-1}X^Ty \\
    &\hat{\sigma^2} = \frac{1}{n - p - 1}\sum_{i = 1}^{n}(y_i - \hat{y_i})^2\quad \text{(unbiased)} \\
    &E(\hat \beta) = \beta \\
    &\mathrm{Var}(\hat \beta) =\sigma^2(X^TX)^{-1}
    \end{aligned}
    $$

2. [MLE](#mle)

$$
\begin{aligned}
&\hat{\beta} = (X^{T}X)^{-1}X^{T}y \\
&\hat{\sigma^2} = \frac{1}{n}\sum_{i = 1}^{n}(y_i - \hat{y_i})^2 = \frac{1}{n} \sum_{i = 1}^{n}\epsilon_i^2 \quad \text{(biased)}\\
&E(\hat{\beta}) = \beta \\
&\mathrm{Var}(\hat{\beta}) =\sigma^2(X^{T}X)^{-1} \\
&\mathrm{Var}(\hat {\sigma^2}) = \frac {2\sigma^4} {n}
\end{aligned}
$$

## Evaluation

1. \(R^2\)

$$
\begin{aligned}
&R^2 = 1 - \frac{SSE}{SST} = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y_i})^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} \\
\end{aligned}
$$
